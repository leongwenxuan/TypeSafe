# Story 9.2: Backend LinkedIn Search Endpoint

<!-- Powered by BMAD™ Core -->

## Status

**Ready for Review**

---

## Story

**As a** backend service,
**I want** a new endpoint that formats LinkedIn searches for Exa,
**so that** the keyboard can trigger profile lookups.

---

## Acceptance Criteria

1. New endpoint: `POST /search-linkedin`
2. Request body:
   ```json
   {
     "prompt": "John Smith software engineer",
     "session_id": "uuid",
     "max_results": 5
   }
   ```
3. Response body:
   ```json
   {
     "type": "linkedin_search",
     "results": [
       {
         "name": "John Smith",
         "title": "Senior Software Engineer",
         "company": "Google",
         "profile_url": "https://linkedin.com/in/johnsmith123",
         "snippet": "Experienced software engineer specializing in..."
       }
     ],
     "search_time_ms": 2340,
     "source": "exa"
   }
   ```
4. Leverages existing `ExaSearchTool` from Epic 8.4
5. LinkedIn-specific query formatting:
   - Template: `"linkedin.com/in/ {prompt}"` or `"{prompt} site:linkedin.com/in/"`
   - Filters Exa results to prioritize LinkedIn profile pages
6. Handles edge cases:
   - Empty prompt → 400 error
   - No results found → Empty array with message
   - Exa API failure → Graceful degradation (error message)
7. Response time: < 5 seconds (p95)
8. Rate limiting: 10 searches per session per hour (prevent abuse)
9. Logs search queries for analytics (anonymized)
10. Integration tests with mock Exa responses

---

## Tasks / Subtasks

- [x] **Task 1: Define Request/Response Models** (AC: 2, 3)
  - [x] Create Pydantic model: `LinkedInSearchRequest` in `backend/app/main.py`
  - [x] Fields: `session_id: str`, `prompt: str`, `max_results: int = 5`
  - [x] Add validators: `session_id` must be valid UUID format
  - [x] Add validators: `prompt` minimum 2 characters, maximum 100 characters
  - [x] Add validators: `max_results` between 1 and 10
  - [x] Create Pydantic model: `LinkedInProfile` for individual profile results
  - [x] Fields: `name: str`, `title: str`, `company: str`, `profile_url: str`, `snippet: str`
  - [x] Create Pydantic model: `LinkedInSearchResponse`
  - [x] Fields: `type: str`, `results: List[LinkedInProfile]`, `search_time_ms: int`, `source: str`
  - [x] Add field defaults: `type = "linkedin_search"`, `source = "exa"`

- [x] **Task 2: Create LinkedIn Search Endpoint** (AC: 1, 4, 5, 6, 7)
  - [x] Add new endpoint in `backend/app/main.py`: `@app.post("/search-linkedin")`
  - [x] Accept `LinkedInSearchRequest` body
  - [x] Return `LinkedInSearchResponse`
  - [x] Import `ExaSearchTool`: `from app.agents.tools.exa_search import get_exa_search_tool`
  - [x] Validate prompt length (2-100 chars), return 400 if invalid
  - [x] Validate session_id is valid UUID, return 400 if invalid
  - [x] Build LinkedIn-specific query: `f'"{prompt}" site:linkedin.com/in/'`
  - [x] Call Exa search with LinkedIn query
  - [x] Measure search duration: `start_time = time.time()`, calculate `search_time_ms`
  - [x] Parse Exa results to extract LinkedIn profiles
  - [x] Handle empty results: Return empty `results` array with appropriate message
  - [x] Handle Exa API errors: Log error, return graceful error response (5XX with message)
  - [x] Ensure response time < 5 seconds (set timeout on Exa call)

- [x] **Task 3: Implement LinkedIn Profile Parser** (AC: 3, 5)
  - [x] Create helper method: `def parse_linkedin_profile(exa_result: Dict) -> Optional[LinkedInProfile]`
  - [x] Extract name from Exa result title (e.g., "John Smith - LinkedIn" → "John Smith")
  - [x] Use regex to extract name: remove " - LinkedIn", " | LinkedIn", etc.
  - [x] Extract job title from snippet (first line or sentence)
  - [x] Extract company name from snippet (pattern: "at [Company]", "@ [Company]")
  - [x] Use regex: `r'(?:at|@)\s+([A-Z][A-Za-z\s&]+)'` to find company
  - [x] Extract profile URL directly from Exa result URL
  - [x] Validate URL is LinkedIn profile: must contain "linkedin.com/in/"
  - [x] Truncate snippet to 200 characters max
  - [x] Return None if URL is not a valid LinkedIn profile (filter out company pages, posts, etc.)
  - [x] Add unit tests for parser with diverse examples

- [x] **Task 4: Add Rate Limiting** (AC: 8)
  - [x] Use Redis to track searches per session
  - [x] Redis key format: `linkedin_search_rate_limit:{session_id}:{hour}`
  - [x] Increment counter on each search
  - [x] Check counter before processing: if >= 10, return 429 error
  - [x] Set TTL on Redis key: 1 hour (3600 seconds)
  - [x] Error message: "Rate limit exceeded. Maximum 10 LinkedIn searches per hour."
  - [x] Log rate limit violations with session_id (anonymized)

- [x] **Task 5: Add Search Analytics Logging** (AC: 9)
  - [x] Create structured log entry on each search
  - [x] Log fields: timestamp, session_id, prompt (anonymized/hashed), result_count, search_time_ms, success/failure
  - [x] Use Python logging: `logger.info()` with JSON-structured format
  - [x] Example: `{"event": "linkedin_search", "session_id": "...", "prompt_hash": "...", "result_count": 5}`
  - [x] Do NOT log full prompt text (privacy concern)
  - [x] Optional: Hash prompt for analytics: `hashlib.sha256(prompt.encode()).hexdigest()[:8]`

- [x] **Task 6: Add New Configuration Settings** (AC: 7, 8)
  - [x] Add to `backend/app/config.py`: `enable_linkedin_search: bool` (default: False for gradual rollout)
  - [x] Add to config: `linkedin_search_rate_limit: int` (default: 10 searches/hour)
  - [x] Add to config: `linkedin_search_timeout: float` (default: 5.0 seconds)
  - [x] Update `.env.example` with new settings
  - [x] Check `enable_linkedin_search` flag in endpoint, return 503 if disabled
  - [x] Error message when disabled: "LinkedIn search feature not available"

- [x] **Task 7: Extend Exa Search Tool for LinkedIn** (AC: 4, 5)
  - [x] Add method to `ExaSearchTool` in `backend/app/agents/tools/exa_search.py`:
  - [x] Method: `async def search_linkedin_profiles(query: str, max_results: int) -> List[Dict]`
  - [x] Override query template for LinkedIn: use `site:linkedin.com/in/` filter
  - [x] Override Exa API params: `category="profile"` (instead of "discussion")
  - [x] Override date filter: remove `start_published_date` (profiles don't have dates)
  - [x] Return raw Exa results (will be parsed by endpoint)
  - [x] Reuse existing caching, timeout, error handling from base class

- [x] **Task 8: Write Unit Tests** (AC: 10)
  - [x] Test file: `backend/tests/test_linkedin_search.py`
  - [x] Test: `test_linkedin_search_valid_request()` - mock Exa, verify 200 response
  - [x] Test: `test_linkedin_search_empty_prompt()` - verify 400 error
  - [x] Test: `test_linkedin_search_prompt_too_short()` - 1 char prompt, verify 400
  - [x] Test: `test_linkedin_search_invalid_session_id()` - non-UUID, verify 400
  - [x] Test: `test_linkedin_search_no_results()` - mock empty Exa response, verify empty array
  - [x] Test: `test_linkedin_search_exa_api_failure()` - mock Exa timeout, verify graceful error
  - [x] Test: `test_linkedin_profile_parser_valid()` - valid LinkedIn result, verify parsing
  - [x] Test: `test_linkedin_profile_parser_invalid_url()` - non-profile URL, verify None returned
  - [x] Test: `test_rate_limiting()` - 11 requests in hour, verify 429 on 11th
  - [x] Test: `test_feature_flag_disabled()` - flag off, verify 503 error
  - [x] Use pytest fixtures to mock Exa API responses
  - [x] Use `pytest-asyncio` for async test support

- [x] **Task 9: Add Integration Test** (AC: 10)
  - [x] Integration test file: `backend/tests/integration/test_linkedin_search_integration.py`
  - [x] Test: `test_linkedin_search_end_to_end()` - real Exa API call (skip if no API key)
  - [x] Use `@pytest.mark.integration` decorator
  - [x] Test with real search: "Satya Nadella Microsoft"
  - [x] Verify response structure matches `LinkedInSearchResponse` model
  - [x] Verify search_time_ms < 5000
  - [x] Verify results contain valid LinkedIn URLs

- [x] **Task 10: Update API Documentation** (AC: 1-3)
  - [x] Add endpoint to FastAPI auto-generated docs (OpenAPI)
  - [x] Ensure Pydantic models have `description` fields
  - [x] Add example values to model fields: `Field(..., examples=[...])`
  - [x] Test Swagger UI: `http://localhost:8000/docs` shows new endpoint
  - [x] Verify request/response schemas display correctly

---

## Dev Notes

### Previous Story Insights

**Story 9.1 (Keyboard Layout Reorganization):**
- Created Prompt button UI in keyboard
- Button triggers `promptButtonTapped()` handler (currently placeholder)
- Story 9.3 will connect keyboard button to this backend endpoint
- Button captures text from `textDocumentProxy` (user's typed input)

**Integration Context:**
- Story 9.2 (this story) creates the backend endpoint
- Story 9.3 will make keyboard call this endpoint via `KeyboardAPIService`
- Endpoint must be ready before Story 9.3 implementation

### Architecture Context

**Source: Backend API Structure** [Source: docs/architecture/public-api-backend.md]
- Existing endpoints follow pattern: `/analyze-text`, `/scan-image`, `/results/latest`
- All use Pydantic models for request/response validation
- Common response schema includes: risk_level, confidence, category, explanation, ts
- Error codes: 400 (invalid input), 429 (rate limit), 500 (provider error)

**Source: Existing FastAPI Patterns** [Source: backend/app/main.py lines 1-100]
- FastAPI app initialized with title, description, version
- CORS middleware configured for iOS app integration
- Request models use Pydantic with validators: `@field_validator`
- Validators check UUID format, text length, whitespace
- Example validator pattern:
```python
@field_validator('session_id')
@classmethod
def validate_session_id(cls, v: str) -> str:
    try:
        uuid.UUID(v)
        return v
    except ValueError:
        raise ValueError('session_id must be a valid UUID')
```

**Source: Exa Search Tool** [Source: backend/app/agents/tools/exa_search.py]
- Existing `ExaSearchTool` class for scam searches
- Base URL: `https://api.exa.ai/search`
- Query templates for different entity types (phone, url, email, etc.)
- Returns `ExaSearchResponse` with `ExaSearchResult` list
- Features: Redis caching (24hr TTL), rate limiting, error handling
- Singleton pattern: `get_exa_search_tool()` function
- Search method: `async def search_scam_reports(entity: str, entity_type: str)`
- API params: `num_results`, `use_autoprompt`, `category`, `start_published_date`

**Source: Exa API Integration** [Source: backend/app/agents/tools/exa_search.py lines 230-285]
- Headers: `{"x-api-key": self.api_key, "Content-Type": "application/json"}`
- POST request to `self.base_url` with JSON payload
- Timeout handling: `httpx.AsyncClient(timeout=self.timeout)`
- Error codes: 429 (rate limit), 401 (auth failed), 5XX (server error)
- Returns: `data.get('results', [])` - list of result dicts
- Result structure: `{title, url, snippet, published_date, score}`

### File Locations

**Primary Implementation Files:**
- `backend/app/main.py` - Add new endpoint, request/response models
  - Add after existing endpoints (around line 200+)
  - Follow pattern of `/analyze-text` endpoint
- `backend/app/agents/tools/exa_search.py` - Add `search_linkedin_profiles()` method
  - Add after line 493 (after `get_exa_search_tool()` function)
- `backend/app/config.py` - Add new configuration settings (lines 100-105)

**Test Files:**
- Create: `backend/tests/test_linkedin_search.py` (unit tests)
- Create: `backend/tests/integration/test_linkedin_search_integration.py` (integration tests)
- Reference pattern: Existing test files in `backend/tests/` (if any exist)

**Environment Configuration:**
- Update: `backend/.env.example` - Document new settings

### Project Structure Notes

**Source Tree Alignment:** [Inferred from existing backend structure]
```
backend/
├── app/
│   ├── main.py                    # Add endpoint here
│   ├── config.py                  # Add settings here
│   ├── agents/
│   │   └── tools/
│   │       └── exa_search.py      # Add method here
│   └── ...
├── tests/
│   ├── test_linkedin_search.py    # Create unit tests
│   └── integration/
│       └── test_linkedin_search_integration.py  # Create integration test
├── .env.example                   # Document new settings
└── requirements.txt               # No new dependencies needed
```

### Data Models

**Source: Database Schema** [Source: docs/architecture/data-model-supabase-postgres.md]
- No new database tables needed for this story
- LinkedIn searches are ephemeral (not stored in database)
- Session tracking uses existing `sessions` table
- Rate limiting uses Redis (not Supabase)

**Rate Limiting Data (Redis):**
- Key: `linkedin_search_rate_limit:{session_id}:{hour}`
- Value: Integer counter (increments per search)
- TTL: 3600 seconds (1 hour)
- Example: `linkedin_search_rate_limit:abc-123:2025-10-20-14` → 5

### Technical Constraints

**Performance Requirements:** [Source: Epic 9, AC: 7]
- Response time: < 5 seconds (p95)
- Set Exa API timeout to 5.0 seconds max
- Measure actual search time and return in response (`search_time_ms`)

**Rate Limiting:** [Source: Epic 9, AC: 8]
- 10 searches per session per hour
- Use Redis for distributed rate limiting
- Return 429 status code when limit exceeded

**Privacy & Security:** [Source: docs/architecture/security-privacy.md]
- Do NOT log full prompt text (contains user's search queries)
- Log hashed prompt for analytics: `sha256(prompt)[:8]`
- Session IDs are UUIDs (anonymized, no PII)

**Cost Management:** [Source: Epic 9]
- Exa API cost: ~$0.005 per search
- Budget: $50/month for 1000 searches
- Reuse Exa caching to reduce redundant API calls
- Cache TTL: 24 hours (configured in settings)

### API Design Patterns to Follow

**Endpoint Naming:** [Source: docs/architecture/public-api-backend.md]
- Use POST for actions (even if read-like): `/search-linkedin`
- All endpoints return JSON
- Use kebab-case for URLs

**Error Response Format:** [Standard FastAPI pattern]
```python
raise HTTPException(
    status_code=400,
    detail="Prompt must be between 2 and 100 characters"
)
```

**Success Response Format:** [Follow existing pattern]
```python
return LinkedInSearchResponse(
    type="linkedin_search",
    results=parsed_profiles,
    search_time_ms=elapsed_ms,
    source="exa"
)
```

### LinkedIn Profile Parsing Logic

**Source: Epic 9 Technical Implementation** [Source: docs/prd/epic-9-exa-linkedin-search-integration.md lines 157-203]

Exa returns results like:
```json
{
  "title": "John Smith - Senior Engineer at Google | LinkedIn",
  "url": "https://linkedin.com/in/johnsmith123",
  "snippet": "Experienced software engineer specializing in distributed systems. Currently at Google..."
}
```

Parser must extract:
- **Name**: Remove " - LinkedIn", " | LinkedIn" from title
  - Regex: `^(.*?)\s*(?:-|\|)\s*.*LinkedIn.*$` → capture group 1
- **Title**: First sentence or line of snippet before "at"
  - Regex: `^([^.]+?)(?:\s+at\s+|\s+@\s+|\.)`
- **Company**: Text after "at" or "@"
  - Regex: `(?:at|@)\s+([A-Z][A-Za-z\s&]+)`
- **Profile URL**: Direct from `url` field (validate contains "linkedin.com/in/")
- **Snippet**: Truncate to 200 chars max

**Edge Cases:**
- No company mentioned → `company = "Unknown"`
- No clear job title → `title = "Professional"` (generic)
- Non-profile URL (e.g., company page) → Return `None` (skip this result)

### Integration with Future Stories

**Story 9.3 Dependencies:**
- Story 9.3 (iOS Keyboard Integration) will call this endpoint via HTTP
- KeyboardAPIService will need new method: `searchLinkedIn(prompt:completion:)`
- Request format will match `LinkedInSearchRequest` model
- Response will be parsed on iOS side to display in popover

### Testing Strategy Details

**Mock Exa Responses:** [For unit tests]
```python
mock_exa_response = {
    "results": [
        {
            "title": "John Smith - Senior Software Engineer | LinkedIn",
            "url": "https://linkedin.com/in/johnsmith123",
            "snippet": "Experienced engineer at Google working on distributed systems...",
            "score": 0.95
        }
    ]
}
```

**Test Fixtures:**
- Create `@pytest.fixture` for mock ExaSearchTool
- Mock `get_exa_search_tool()` function
- Mock `search_linkedin_profiles()` to return test data
- Use `pytest-mock` or `unittest.mock`

**Integration Test Considerations:**
- Skip integration test if `EXA_API_KEY` not set in environment
- Use `@pytest.mark.skipif(not os.getenv('EXA_API_KEY'), reason="No API key")`
- Limit integration test to 1-2 searches (cost control)

---

## Testing

### Testing Standards

**Test File Location:** [Source: docs/architecture/observability-testing.md]
- Unit tests: `backend/tests/test_linkedin_search.py`
- Integration tests: `backend/tests/integration/test_linkedin_search_integration.py`
- Follow pytest conventions: test functions start with `test_`

**Testing Frameworks:** [Inferred from backend structure]
- pytest - Python testing framework
- pytest-asyncio - For async function testing
- httpx or requests-mock - For mocking HTTP requests
- pytest-mock - For mocking dependencies

**Test Structure Pattern:**
```python
import pytest
from fastapi.testclient import TestClient
from unittest.mock import AsyncMock, patch

from app.main import app

client = TestClient(app)

@pytest.mark.asyncio
async def test_linkedin_search_valid_request():
    """Test successful LinkedIn search with valid prompt."""
    # Arrange
    mock_exa_response = {...}

    with patch('app.agents.tools.exa_search.ExaSearchTool.search_linkedin_profiles') as mock_search:
        mock_search.return_value = mock_exa_response

        # Act
        response = client.post("/search-linkedin", json={
            "prompt": "John Smith",
            "session_id": "123e4567-e89b-12d3-a456-426614174000",
            "max_results": 5
        })

        # Assert
        assert response.status_code == 200
        data = response.json()
        assert data["type"] == "linkedin_search"
        assert len(data["results"]) > 0
        assert data["source"] == "exa"
```

**Specific Testing Requirements:**
- All endpoint validation errors must have unit tests
- Rate limiting must be tested with Redis mock
- Parser must handle malformed LinkedIn URLs
- Async functions require `@pytest.mark.asyncio` decorator
- Use FastAPI `TestClient` for endpoint testing

**Performance Testing:**
- Mock Exa to return instantly, verify endpoint responds < 100ms
- Integration test should measure actual Exa response time
- Log performance metrics in tests for monitoring

---

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-10-20 | 1.0 | Initial story draft created | Bob (Scrum Master) |

---

## Dev Agent Record

### Agent Model Used

Claude Sonnet 4.5 (claude-sonnet-4-5-20250929)

### Debug Log References

No debug log entries were required for this story. All implementation proceeded without blocking issues.

### Completion Notes

**Implementation Summary:**

Successfully implemented all 10 tasks for the LinkedIn Search endpoint (Story 9.2). All acceptance criteria met and validated through comprehensive testing.

**Key Accomplishments:**

1. **Pydantic Models** - Created LinkedInSearchRequest, LinkedInProfile, and LinkedInSearchResponse with full validation
2. **Endpoint Implementation** - POST /search-linkedin endpoint with complete error handling and feature flag
3. **Profile Parser** - Robust regex-based parser extracting name, title, company from Exa results with fallback handling
4. **Rate Limiting** - Redis-based rate limiting (10 searches/session/hour) with graceful degradation on Redis failure
5. **Analytics Logging** - Privacy-safe structured JSON logging with SHA256 prompt hashing
6. **Configuration** - Added 3 new settings (enable_linkedin_search, linkedin_search_rate_limit, linkedin_search_timeout)
7. **Exa Integration** - New search_linkedin_profiles() method with LinkedIn-specific query template
8. **Unit Tests** - 18 comprehensive tests covering all edge cases (18/18 passing)
9. **Integration Tests** - 4 end-to-end tests with real Exa API calls (skippable if no API key)
10. **API Documentation** - FastAPI auto-generates OpenAPI docs with full request/response schemas

**Testing Results:**

- All 18 unit tests pass (100% success rate)
- Parser correctly handles various LinkedIn title formats
- Validation properly rejects invalid inputs (empty prompt, non-UUID session_id, out-of-range max_results)
- Rate limiting correctly enforces 10 searches/hour limit
- Feature flag correctly blocks requests when disabled
- Non-profile URLs (company pages, jobs) are filtered out

**Technical Decisions:**

- Used inline import of get_exa_search_tool() in endpoint to avoid circular dependencies
- Parser uses defensive programming with fallbacks ("Unknown" company, "Professional" title) rather than failing
- Rate limiting continues on Redis failure (logged but non-blocking) for availability
- Prompt hashing uses SHA256[:8] for analytics while protecting user privacy
- Integration tests use @pytest.mark.integration and skip if EXA_API_KEY not set

**No Issues or Technical Debt:**

- All code follows existing patterns from analyze-text endpoint
- No new dependencies added (reused existing FastAPI, Pydantic, Redis, httpx)
- No linter errors or warnings introduced
- All error paths tested and handled gracefully

### File List

**Modified Files:**

- backend/app/main.py - Added models (lines 179-296), parser (lines 303-389), endpoint (lines 1047-1234)
- backend/app/config.py - Added 3 LinkedIn settings (lines 107-121)
- backend/app/agents/tools/exa_search.py - Added search_linkedin_profiles() method (lines 473-555)
- backend/.env.example - Added 3 LinkedIn config examples (lines 18-21)

**New Files:**

- backend/tests/test_linkedin_search.py - 18 unit tests (467 lines)
- backend/tests/integration/test_linkedin_search_integration.py - 4 integration tests (227 lines)
- backend/tests/integration/__init__.py - Integration tests module init

---

## QA Results
*To be filled by QA Agent*
